import{b as n,o as a,w as i,g as e,a9 as t,v as u,x as c,C as r}from"./modules/vue-j41QyVbg.js";import{I as d}from"./slidev/default-CxLWDW9T.js";import{u as m,f as p}from"./slidev/context-b2JJ8EB_.js";import"./index-BiU4ZQ3P.js";import"./modules/shiki-C01_B2YW.js";const b={__name:"slide.md__slidev_16",setup(h){const{$clicksContext:l,$frontmatter:s}=m();return l.setup(),(f,o)=>(a(),n(d,u(c(r(p)(r(s),15))),{default:i(()=>o[0]||(o[0]=[e("h1",null,"Metrics",-1),e("ul",null,[e("li",null,[t("Adopt automated metrics for low-cost, fast, and consistent. "),e("ul",null,[e("li",null,[e("code",null,"Is this ___?"),t(" => "),e("code",null,"Answer the multiple choice question by just giving the letter of the correct answer. Is this ___? (a) Yes (b) No")]),e("li",null,[t("Open-ended answer: "),e("strong",null,"Prometheus-Vision"),t(" score "),e("ul",null,[e("li",null,"VLM that judges the similarity between the prediction and the ground truth on a scale of 1 (bad) to 5 (good)")])]),e("li",null,"Perspective API toxicity classifier for toxic aspect")])]),e("li",null,"Average the score for each scenario"),e("li",null,[t("Compute the "),e("span",{color:"red"},"mean win rate"),t(" on the main metrics when creating the overall leaderboard or ranking the models within an aspect.")])],-1)])),_:1},16))}};export{b as default};
