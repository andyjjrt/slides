import{b as a,o as u,w as r,g as l,ad as n,v as i,x as g,T as e}from"./modules/vue-CExxo5Y-.js";import{I as p}from"./slidev/default-D_bHMWDv.js";import{u as d,f as c}from"./slidev/context-BzMuSdlI.js";import"./index-BoNHALzr.js";import"./modules/shiki-3ci1IloS.js";const L={__name:"slides.md__slidev_12",setup(m){const{$clicksContext:s,$frontmatter:o}=d();return s.setup(),(h,t)=>(u(),a(p,i(g(e(c)(e(o),11))),{default:r(()=>[...t[0]||(t[0]=[l("h1",null,"Experiment",-1),l("ul",null,[l("li",null,[l("strong",null,"Datasets (Long-Context & Reasoning)"),l("ul",null,[l("li",null,[l("strong",null,"Summarization (LongBench):"),n(" GovReport, QMSum, Multi-News "),l("span",null,"1"),n(".")]),l("li",null,[l("strong",null,"Code Completion (LongBench):"),n(" LCC, RepoBench-P "),l("span",null,"1"),n(".")]),l("li",null,[l("strong",null,"Long Reasoning:"),n(" AIME24 (tested on the reasoning model QwQ-32B) "),l("span",null,"2"),n(".")])])]),l("li",null,[l("strong",null,"Target Models"),l("ul",null,[l("li",null,[n("Evaluated on "),l("strong",null,"Vicuna"),n(" (7B, 13B), "),l("strong",null,"LongChat"),n(" (7B, 13B), "),l("strong",null,"LLaMA-3.1-8B-Instruct"),n(", and "),l("strong",null,"QwQ-32B"),n(),l("span",null,"3"),n(", "),l("span",null,"4"),n(".")])])]),l("li",null,[l("strong",null,"Comparisons & Baselines"),l("ul",null,[l("li",null,[l("strong",null,"Vanilla HF:"),n(" Standard HuggingFace attention (PyTorch-based) "),l("span",null,"2"),n(".")]),l("li",null,[l("strong",null,"Vanilla FA:"),n(" Strong baseline using "),l("strong",null,"Flash Attention"),n(" (FlashDecoding) "),l("span",null,"2"),n(".")]),l("li",null,[l("strong",null,"MagicDec:"),n(" A state-of-the-art method that uses the target model with sparse KV cache as the drafter "),l("span",null,"2"),n(".")])])])],-1)])]),_:1},16))}};export{L as default};
