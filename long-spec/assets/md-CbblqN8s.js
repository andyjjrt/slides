import{b as n,o as s,w as i,g as e,ad as t,v as u,x as c,T as a}from"./modules/vue-CExxo5Y-.js";import{I as p}from"./slidev/default-D_bHMWDv.js";import{u as d,f as m}from"./slidev/context-BzMuSdlI.js";import"./index-BoNHALzr.js";import"./modules/shiki-3ci1IloS.js";const y={__name:"slides.md__slidev_5",setup(f){const{$clicksContext:r,$frontmatter:l}=d();return r.setup(),(g,o)=>(s(),n(p,u(c(a(m)(a(l),4))),{default:i(()=>[...o[0]||(o[0]=[e("h1",null,"Related Work",-1),e("p",null,"Existing Long-Context Acceleration",-1),e("p",null,[e("strong",null,"Overview:"),t(" A few recent frameworks have attempted to adapt speculative decoding specifically for long-context scenarios.")],-1),e("ul",null,[e("li",null,[e("strong",null,"Target-as-Draft Approaches:"),t(" Methods like "),e("strong",null,"TriForce"),t(", "),e("strong",null,"MagicDec"),t(", and "),e("strong",null,"QuantSpec"),t(" typically use the target model itself (or a version of it) as the draft model.")]),e("li",null,[e("strong",null,"Compression Techniques:"),t(" To make the target model faster for drafting, they employ techniques like sparse Key-Value (KV) caches or 4-bit quantization.")]),e("li",null,[e("strong",null,"Goal:"),t(" These aim to handle the extended memory requirements of long sequences without training a separate lightweight architecture.")])],-1)])]),_:1},16))}};export{y as default};
