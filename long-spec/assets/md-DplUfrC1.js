import{b as n,o as a,w as i,g as e,ad as o,v as c,x as u,T as r}from"./modules/vue-CExxo5Y-.js";import{I as d}from"./slidev/default-D_bHMWDv.js";import{u as m,f}from"./slidev/context-BzMuSdlI.js";import"./index-BoNHALzr.js";import"./modules/shiki-3ci1IloS.js";const y={__name:"slides.md__slidev_2",setup(p){const{$clicksContext:l,$frontmatter:s}=m();return l.setup(),(g,t)=>(a(),n(d,c(u(r(f)(r(s),1))),{default:i(()=>[...t[0]||(t[0]=[e("h1",null,"Introduction",-1),e("ul",null,[e("li",null,"Challenge: While Speculative Decoding (SD) accelerates LLMs, state-of-the-art methods struggle with long contexts (100k+ tokens) due to prohibitive memory demands and training data scarcity."),e("li",null,[o("Solution: "),e("strong",null,"LONGSPEC"),o(" provides a framework for lossless acceleration specifically designed for long-context scenarios "),e("ul",null,[e("li",null,"Memory-Efficient Architecture"),e("li",null,"Anchor-Offset Indices"),e("li",null,"Hybrid Tree Attention")])])],-1)])]),_:1},16))}};export{y as default};
