import{b as a,o as l,w as r,g as e,ad as t,v as d,x as c,T as n}from"./modules/vue-CExxo5Y-.js";import{I as u}from"./slidev/default-D_bHMWDv.js";import{u as m,f as p}from"./slidev/context-BzMuSdlI.js";import"./index-BoNHALzr.js";import"./modules/shiki-3ci1IloS.js";const v={__name:"slides.md__slidev_6",setup(g){const{$clicksContext:s,$frontmatter:i}=m();return s.setup(),(f,o)=>(l(),a(u,d(c(n(p)(n(i),5))),{default:r(()=>[...o[0]||(o[0]=[e("h1",null,"Problem",-1),e("ul",null,[e("li",null,[e("p",null,[t("Existing solutions cannot solve the specific problems addressed by "),e("strong",null,"LONGSPEC"),t(" due to three critical limitations:")]),e("ol",null,[e("li",null,[e("strong",null,"Memory Bottlenecks (Standard SD)"),t(": SoTA methods like EAGLE are trained on short texts (<4k tokens). Their KV cache grows linearly, causing prohibitive memory usage when applied to long contexts (100k+ tokens).")]),e("li",null,[e("strong",null,"Training-Inference Mismatch"),t(': Models trained on abundant short sequences fail to generalize to long contexts due to "out-of-distribution" position indices. Standard RoPE extrapolation fails because draft models must match the target modelâ€™s fixed base.')]),e("li",null,[e("strong",null,"Inefficient Drafting (Existing Long-Context SD)"),t(": Methods like MagicDec rely on heavy target models (even with sparse KV). This remains computation-intensive, limiting speedups especially in low-batch scenarios compared to a dedicated lightweight drafter.")])])])],-1)])]),_:1},16))}};export{v as default};
