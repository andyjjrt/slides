import{o as a,c as o,k as i,e,a9 as l,q as u,s as c,B as t}from"./modules/vue-6mTy9ZQF.js";import{I as p}from"./slidev/default-B8RdL-hL.js";import{u as m,f as d}from"./slidev/context-_fRd7GMj.js";import"./index-aaSGCAS-.js";import"./modules/shiki-BzntFxfw.js";const f="/page-attention/Experiment/Setup.png",A={__name:"slide.md__slidev_25",setup(g){const{$slidev:_,$nav:x,$clicksContext:n,$clicks:v,$page:B,$renderContext:h,$frontmatter:s}=m();return n.setup(),(O,r)=>(a(),o(p,u(c(t(d)(t(s),24))),{default:i(()=>r[0]||(r[0]=[e("h1",null,"Experimental Setup",-1),e("ul",null,[e("li",null,[e("strong",null,"Model"),l(": OPT 13B, 66B, 175B, Llama 13B")]),e("li",null,[e("strong",null,"Server"),l(": A2 instance of NVIDIA A100 GPUs on Google Cloud")]),e("li",null,[e("strong",null,"Workload"),l(": ShareGPT, Alpaca")]),e("li",null,[e("strong",null,"Baseline"),l(": "),e("ul",null,[e("li",null,[l("FasterTransformer: Distributed inference engine highly "),e("br"),l(" optimized for latency.")]),e("li",null,[l("Orca: SOTA LLM serving system optimized for throughput. "),e("ul",null,[e("li",null,"Orca(Oracle): reserved space == real space"),e("li",null,"Orca(Pow2): reserved space <= 2x real space"),e("li",null,[l("Orca(Oracle): reserved space == "),e("code",null,"MAX_LENGTH")])])])])]),e("li",null,[e("strong",null,"Key metrics"),l(": "),e("em",null,"normalized latency"),l(" of the system")])],-1),e("img",{src:f,class:"abs-tr top-24 right-5 w-96"},null,-1)])),_:1},16))}};export{A as default};
