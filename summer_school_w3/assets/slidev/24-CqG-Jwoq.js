import{I as g}from"./default-aFPF9ihK.js";import{b as f,X as i}from"../index-CHd_ipKT.js";import{p as u,u as d,f as x}from"./context-C9gyYOJl.js";import{o as v,c as h,k as $,q as k,s as b,e,$ as r}from"../modules/vue-jJv3i-5y.js";import"../modules/shiki-DNME4isg.js";const y={__name:"24",setup(c,{expose:n}){n(),u(i);const{$slidev:o,$nav:t,$clicksContext:a,$clicks:s,$page:m,$renderContext:p,$frontmatter:_}=d(),l={$slidev:o,$nav:t,$clicksContext:a,$clicks:s,$page:m,$renderContext:p,$frontmatter:_,InjectedLayout:g,get frontmatter(){return i},get useSlideContext(){return d},get _provideFrontmatter(){return u},get _frontmatterToProps(){return x}};return Object.defineProperty(l,"__isScriptSetup",{enumerable:!1,value:!0}),l}},C=e("h1",null,"Exposure bias",-1),P=e("ul",null,[e("li",null,"During training, modelâ€™s inputs are gold texts from real, human-generated texts. But at generation time, modelâ€™s inputs are previously-decoded tokens"),e("li",null,[r("Solutions "),e("ul",null,[e("li",null,[e("strong",null,"Scheduled sampling"),r(": A small percentage to decode a token rather than fold texts, but may lead to "),e("strong",{color:"red"},"strange training objective")]),e("li",null,[e("strong",null,"Dataset Aggregation"),r(": Generate sequences from current model, and add these sequences as extra training data")]),e("li",null,[e("strong",null,"Retrieval Augmentation"),r(": Learn to retrieve a sequence from an existing corpus of human-written prototypes")]),e("li",null,[e("strong",null,"Reinforcement Learning"),r(": Cast text generation model as a Markov decision process")])])])],-1);function S(c,n,o,t,a,s){return v(),h(t.InjectedLayout,k(b(t._frontmatterToProps(t.frontmatter,23))),{default:$(()=>[C,P]),_:1},16)}const A=f(y,[["render",S],["__file","/@slidev/slides/24.md"]]);export{A as default};
