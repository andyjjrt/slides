import{_}from"./SlideCurrentNo-DXh9C2ha.js";import{I as g}from"./default-C78aYwz8.js";import{b as x,G as p}from"../index-9B86silg.js";import{p as m,u,f as v}from"./context-BT4Oe31f.js";import{o as P,c as $,k as b,e as t,$ as o,l as y,q as C,s as k}from"../modules/vue-C2_u18UA.js";import"../modules/shiki-B_Yc-FM6.js";const S={__name:"7",setup(c,{expose:e}){e(),m(p);const{$slidev:a,$nav:r,$clicksContext:s,$clicks:i,$page:n,$renderContext:d,$frontmatter:f}=u(),l={$slidev:a,$nav:r,$clicksContext:s,$clicks:i,$page:n,$renderContext:d,$frontmatter:f,InjectedLayout:g,get frontmatter(){return p},get useSlideContext(){return u},get _provideFrontmatter(){return m},get _frontmatterToProps(){return v}};return Object.defineProperty(l,"__isScriptSetup",{enumerable:!1,value:!0}),l}};function h(c,e,a,r,s,i){const n=_;return P(),$(r.InjectedLayout,C(k(r._frontmatterToProps(r.frontmatter,6))),{default:b(()=>[e[0]||(e[0]=t("h1",null,"DPO - Direct Preference Optimization",-1)),e[1]||(e[1]=t("p",null,[t("img",{src:"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/pref_tuning/dpo.png",alt:""})],-1)),e[2]||(e[2]=t("ul",null,[t("li",null,[o("Rather than using "),t("span",{color:"red"},"reward modeling"),o(" and "),t("span",{color:"red"},"reinforcement learning"),o(", DPO leverages a unique "),t("span",{color:"red"},"parameterization reward"),o(" functions to extract the optimal policy directly.")])],-1)),y(n,{class:"absolute bottom-4 right-6 text-sm text-gray-400"})]),_:1},16)}const B=x(S,[["render",h],["__file","/@slidev/slides/7.md"]]);export{B as default};
